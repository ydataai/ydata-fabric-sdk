{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>YData SDK for improved data quality everywhere!</p> <p>ydata-sdk is here! Create a YData account so you can start using today!</p> <p>Create account</p>"},{"location":"#overview","title":"Overview","text":"<p>The YData SDK is an ecosystem of methods that allows users to, through a python interface, adopt a Data-Centric approach towards the AI development. The solution includes a set of integrated components for data ingestion, standardized data quality evaluation and data improvement, such as synthetic data generation, allowing an iterative improvement of the datasets used in high-impact business applications.</p> <p>Synthetic data can be used as Machine Learning performance enhancer, to augment or mitigate the presence of bias in real data. Furthermore, it can be used as a Privacy Enhancing Technology, to enable data-sharing initiatives or even to fuel testing environments.</p> <p>Under the YData-SDK hood, you can find a set of algorithms and metrics based on statistics and deep learning based techniques, that will help you to accelerate your data preparation.</p>"},{"location":"#current-functionality","title":"Current functionality","text":"<p>YData SDK is currently composed by the following main modules:</p> <ul> <li> <p>Datasources</p> <ul> <li>YData\u2019s SDK includes several connectors for easy integration with existing data sources. It supports several storage types, like filesystems and RDBMS. Check the list of connectors.</li> <li>SDK\u2019s Datasources run on top of Dask, which allows it to deal with not only small workloads but also larger volumes of data.</li> </ul> </li> <li> <p>Synthesizers</p> <ul> <li>Simplified interface to train a generative model and learn in a data-driven manner the behavior, the patterns and original data distribution. Optimize your model for privacy or utility use-cases.</li> <li>From a trained synthesizer, you can generate synthetic samples as needed and parametrise the number of records needed.</li> </ul> </li> <li> <p>Synthetic data quality report Coming soon</p> <ul> <li>An extensive synthetic data quality report that measures 3 dimensions: privacy, utility and fidelity of the generated data. The report can be downloaded in PDF format for ease of sharing and compliance purposes or as a JSON to enable the integration in data flows.</li> </ul> </li> <li> <p>Profiling Coming soon</p> <ul> <li>A set of metrics and algorithms summarizes datasets quality in three main dimensions: warnings, univariate analysis and a multivariate perspective.</li> </ul> </li> </ul>"},{"location":"#supported-data-formats","title":"Supported data formats","text":"TabularTime-SeriesTransactionalRelational databases <p> The RegularSynthesizer is perfect to synthesize high-dimensional data, that is time-indepentent with high quality results.</p> <p>Know more</p> <p> The TimeSeriesSynthesizer is perfect to synthesize both regularly and not evenly spaced time-series, from smart-sensors to stock.</p> <p>Know more</p> <p> The TimeSeriesSynthesizer supports transactional data, known to have highly irregular time intervals between records and directional relations between entities.</p> <p>Coming soon</p> <p>Know more</p> <p> The MultiTableSynthesizer is perfect to learn how to replicate the data within a relational database schema.</p> <p>Coming soon</p> <p>Know more</p>"},{"location":"examples/synthesize_tabular_data/","title":"Synthesize tabular data","text":"<p>Use YData's RegularSynthesizer to generate tabular synthetic data</p> <pre><code>import os\nfrom ydata.sdk.dataset import get_dataset\nfrom ydata.sdk.synthesizers import RegularSynthesizer\n# Do not forget to add your token as env variables\nos.environ[\"YDATA_TOKEN\"] = '&lt;TOKEN&gt;'  # Remove if already defined\ndef main():\n\"\"\"In this example, we demonstrate how to train a synthesizer from a pandas\n    DataFrame.\n    After training a Regular Synthesizer, we request a sample.\n    \"\"\"\nX = get_dataset('census')\n# We initialize a regular synthesizer\n# As long as the synthesizer does not call `fit`, it exists only locally\nsynth = RegularSynthesizer()\n# We train the synthesizer on our dataset\nsynth.fit(X)\n# We request a synthetic dataset with 50 rows\nsample = synth.sample(n_samples=50)\nprint(sample.shape)\nif __name__ == \"__main__\":\nmain()\n</code></pre>"},{"location":"examples/synthesize_timeseries_data/","title":"Synthesize time-series data","text":"<p>Use YData's TimeSeriesSynthesizer to generate time-series synthetic data</p> <p>Tabular data is the most common type of data we encounter in data problems.</p> <p>When thinking about tabular data, we assume independence between different records, but this does not happen in reality. Suppose we check events from our day-to-day life, such as room temperature changes, bank account transactions, stock price fluctuations, and air quality measurements in our neighborhood. In that case, we might end up with datasets where measures and records evolve and are related through time. This type of data is known to be sequential or time-series data.</p> <p>Thus, sequential or time-series data refers to any data containing elements ordered into sequences in a structured format. Dissecting any time-series dataset, we see differences in variables' behavior that need to be understood for an effective generation of synthetic data. Typically any time-series dataset is composed of the following:</p> <ul> <li>Variables that define the order of time (these can be simple with one variable or composed)</li> <li>Time-variant variables</li> <li>Variables that refer to entities (single or multiple entities)</li> <li>Variables that are attributes (those that don't depend on time but rather on the entity)</li> </ul> <p>Below find an example:</p> <pre><code>import os\nfrom ydata.sdk.dataset import get_dataset\nfrom ydata.sdk.synthesizers import TimeSeriesSynthesizer\n# Do not forget to add your token as env variable\nos.environ[\"YDATA_TOKEN\"] = '&lt;TOKEN&gt;'\nX = get_dataset('occupancy')\n# We initialize a time series synthesizer\n# As long as the synthesizer does not call `fit`, it exists only locally\nsynth = TimeSeriesSynthesizer()\n# We train the synthesizer on our dataset\n# sortbykey -&gt; variable that define the time order for the sequence\nsynth.fit(X, sortbykey='date')\n# By default it is requested a synthetic sample with the same length as the original data\n# The TimeSeriesSynthesizer is designed to replicate temporal series and therefore the original time-horizon is respected\nsample = synth.sample(n_entities=1)\n</code></pre>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>YData SDK is generally available through both Pypi and Conda allowing an easy process of installation. This experience allows combining YData SDK with other packages such as Pandas, Numpy or Scikit-Learn.</p> <p>YData SDK is available for the public through a token-based authentication system. If you don\u2019t have one yet, you can get your free license key during the installation process. You can check what features are available in the free version here.</p>"},{"location":"getting-started/installation/#installing-the-package","title":"Installing the package","text":"<p>YData SDK supports python versions bigger than python 3.8, and can be installed in Windows, Linux or MacOS operating systems.</p> <p>Prior to the package installation, it is recommended the creation of a virtual or conda environment:</p> pyenv <pre><code>pyenv virtualenv 3.10 ydatasdk\n</code></pre> <p>And install <code>ydata-sdk</code></p> pypi <pre><code>pip install ydata-sdk\n</code></pre>"},{"location":"getting-started/installation/#authentication","title":"Authentication","text":"<p>Once you've installed <code>ydata-sdk</code> package you will need a token to run the functionalities. YData SDK uses a token based authentication system. To get access to your token, you need to create a YData account.</p> <p>YData SDK offers a free-trial and an enterprise version. To access your free-trial token, you need to create a YData account.</p> <p>The token will be available here, after login:</p> <p></p> <p>With your account toke copied, you can set a new environment variable <code>YDATA_TOKEN</code> in the beginning of your development session.</p> <pre><code>    import os\nos.setenv['YDATA_TOKEN'] = '{add-your-token}'\n</code></pre> <p>Once you have set your token, you are good to go to start exploring the incredible world of data-centric AI and smart synthetic data generation!</p> <p>Check out our quickstart guide!</p>"},{"location":"getting-started/quickstart/","title":"Quickstart","text":"<p>YData SDK allows you to with an easy and familiar interface, to adopt a Data-Centric AI approach for the development of Machine Learning solutions. YData SDK features were designed to support structure data, including tabular data, time-series and transactional data.</p>"},{"location":"getting-started/quickstart/#read-data","title":"Read data","text":"<p>To start leveraging the package features you should consume your data either through the Connectors or pandas.Dataframe. The list of available connectors can be found here [add a link].</p> From pandas dataframeFrom a connector <pre><code>    # Example for a Google Cloud Storage Connector\ncredentials = \"{insert-credentials-file-path}\"\n# We create a new connector for Google Cloud Storage\nconnector = Connector(connector_type='gcs', credentials=credentials)\n# Create a Datasource from the connector\n# Note that a connector can be re-used for several datasources\nX = DataSource(connector=connector, path='gs://&lt;my_bucket&gt;.csv')\n</code></pre> <pre><code>    # Load a small dataset\nX = pd.read_csv('{insert-file-path.csv}')\n# Init a synthesizer\nsynth = RegularSynthesizer()\n# Train the synthesizer with the pandas Dataframe as input\n# The data is then sent to the cluster for processing\nsynth.fit(X)\n</code></pre> <p>The synthesis process returns a <code>pandas.DataFrame</code> object. Note that if you are using the <code>ydata-sdk</code> free version, all of your data is sent to a remote cluster on YData's infrastructure.</p>"},{"location":"getting-started/quickstart/#data-synthesis-flow","title":"Data synthesis flow","text":"<p>The process of data synthesis can be described into the following steps:</p> <pre><code>stateDiagram-v2\n  state read_data\n  read_data --&gt; init_synth\n  init_synth --&gt; train_synth\n  train_synth --&gt; generate_samples\n  generate_samples --&gt; [*]</code></pre> <p>The code snippet below shows how easy can be to start generating new synthetic data. The package includes a set of examples datasets for a quickstart.</p> <pre><code>    from ydata.sdk.dataset import get_dataset\n#read the example data\nX = get_dataset('census')\n# Init a synthesizer\nsynth = RegularSynthesizer()\n# Fit the synthesizer to the input data\nsynth.fit(X)\n# Sample new synthetic data. The below request ask for new 1000 synthetic rows\nsynth.sample(n_samples=1000)\n</code></pre> <p>Do I need to prepare my data before synthesis?</p> <p>The sdk ensures that the original behaviour is replicated. For that reason, there is no need to preprocess outlier observations or missing data.</p> <p>By default all the missing data is replicated as NaN.</p>"},{"location":"modules/connectors/","title":"Connectors","text":"<p>YData SDK allows users to consume data assets from remote storages through Connectors. YData Connectors support different types of storages, from filesystems to RDBMS'.</p> <p>Below the list of available connectors:</p> Connector Name Type Supported File Types Useful Links Notes AWS S3 Remote object storage CSV, Parquet https://aws.amazon.com/s3/ Google Cloud Storage Remote object storage CSV, Parquet https://cloud.google.com/storage Azure Blob Storage Remote object storage CSV, Parquet https://azure.microsoft.com/en-us/services/storage/blobs/ File Upload Local CSV - Maximum file size is 220MB. Bigger files should be uploaded and read from remote object storages MySQL RDBMS Not applicable https://www.mysql.com/ Supports reading whole schemas or specifying a query Azure SQL Server RDBMS Not applicable https://azure.microsoft.com/en-us/services/sql-database/campaign/ Supports reading whole schemas or specifying a query PostgreSQL RDBMS Not applicable https://www.postgresql.org/ Supports reading whole schemas or specifying a query Snowflake RDBMS Not applicable https://docs.snowflake.com/en/sql-reference-commands Supports reading whole schemas or specifying a query Google BigQuery Data warehouse Not applicable https://cloud.google.com/bigquery Azure Data Lake Data lake CSV, Parquet https://azure.microsoft.com/en-us/services/storage/data-lake-storage/ <p>More details can be found at Connectors APi Reference Docs.</p>"},{"location":"modules/synthetic_data/","title":"Synthetic data generation","text":""},{"location":"modules/synthetic_data/#data-formats","title":"Data formats","text":""},{"location":"modules/synthetic_data/#tabular-data","title":"Tabular data","text":""},{"location":"modules/synthetic_data/#time-series-data","title":"Time-series data","text":""},{"location":"modules/synthetic_data/#transactions-data","title":"Transactions data","text":""},{"location":"modules/synthetic_data/#best-practices","title":"Best practices","text":""},{"location":"reference/api/common/client/","title":"Get client","text":"<p>Deduce how to initialize or retrieve the client.</p> <p>This is meant to be a zero configuration for the user.</p> Create and set a client globally <pre><code>from ydata.sdk.client import get_client\nget_client(set_as_global=True)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>client_or_creds</code> <code>Optional[Union[Client, dict, str, Path]]</code> <p>Client to forward or credentials for initialization</p> <code>None</code> <code>set_as_global</code> <code>bool</code> <p>If <code>True</code>, set client as global</p> <code>False</code> <code>wait_for_auth</code> <code>bool</code> <p>If <code>True</code>, wait for the user to authenticate</p> <code>True</code> <p>Returns:</p> Type Description <code>Client</code> <p>Client instance</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/common/client/utils.py</code> <pre><code>def get_client(client_or_creds: Optional[Union[Client, Dict, str, Path]] = None, set_as_global: bool = False, wait_for_auth: bool = True) -&gt; Client:\n\"\"\"Deduce how to initialize or retrieve the client.\n    This is meant to be a zero configuration for the user.\n    Example: Create and set a client globally\n            ```py\n            from ydata.sdk.client import get_client\n            get_client(set_as_global=True)\n            ```\n    Args:\n        client_or_creds (Optional[Union[Client, dict, str, Path]]): Client to forward or credentials for initialization\n        set_as_global (bool): If `True`, set client as global\n        wait_for_auth (bool): If `True`, wait for the user to authenticate\n    Returns:\n        Client instance\n    \"\"\"\nclient = None\nglobal WAITING_FOR_CLIENT\ntry:\n# If a client instance is set globally, return it\nif not set_as_global and Client.GLOBAL_CLIENT is not None:\nreturn Client.GLOBAL_CLIENT\n# Client exists, forward it\nif isinstance(client_or_creds, Client):\nreturn client_or_creds\n# Explicit credentials\n''' # For the first version, we deactivate explicit credentials via string or file for env var only\n        if isinstance(client_or_creds, (dict, str, Path)):\n            if isinstance(client_or_creds, str):  # noqa: SIM102\n                if Path(client_or_creds).is_file():\n                    client_or_creds = Path(client_or_creds)\n            if isinstance(client_or_creds, Path):\n                client_or_creds = json.loads(client_or_creds.open().read())\n            return Client(credentials=client_or_creds)\n        # Last try with environment variables\n        #if client_or_creds is None:\n        client = _client_from_env(wait_for_auth=wait_for_auth)\n        '''\ncredentials = environ.get(TOKEN_VAR)\nif credentials is not None:\nclient = Client(credentials=credentials)\nexcept ClientHandshakeError as e:\nwait_for_auth = False  # For now deactivate wait_for_auth until the backend is ready\nif wait_for_auth:\nWAITING_FOR_CLIENT = True\nstart = time()\nlogin_message_printed = False\nwhile client is None:\nif not login_message_printed:\nprint(\nf\"The token needs to be refreshed - please validate your token by browsing at the following URL:\\n\\n\\t{e.auth_link}\")\nlogin_message_printed = True\nwith suppress(ClientCreationError):\nsleep(BACKOFF)\nclient = get_client(wait_for_auth=False)\nnow = time()\nif now - start &gt; CLIENT_INIT_TIMEOUT:\nWAITING_FOR_CLIENT = False\nbreak\nif client is None and not WAITING_FOR_CLIENT:\nsys.tracebacklimit = None\nraise ClientCreationError\nreturn client\n</code></pre> <p>Main Client class used to abstract the connection to the backend.</p> <p>A normal user should not have to instanciate a <code>Client</code> by itself. However, in the future it will be useful for power-users to manage projects and connections.</p> <p>Parameters:</p> Name Type Description Default <code>credentials</code> <code>Optional[dict]</code> <p>(optional) Credentials to connect</p> <code>None</code> <code>project</code> <code>Optional[Project]</code> <p>(optional) Project to connect to. If not specified, the client will connect to the default user's project.</p> <code>None</code> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/common/client/client.py</code> <pre><code>@typechecked\nclass Client(metaclass=SingletonClient):\n\"\"\"Main Client class used to abstract the connection to the backend.\n    A normal user should not have to instanciate a [`Client`][ydata.sdk.common.client.Client] by itself.\n    However, in the future it will be useful for power-users to manage projects and connections.\n    Args:\n        credentials (Optional[dict]): (optional) Credentials to connect\n        project (Optional[Project]): (optional) Project to connect to. If not specified, the client will connect to the default user's project.\n    \"\"\"\ncodes = codes\ndef __init__(self, credentials: Optional[Union[str, Dict]] = None, project: Optional[Project] = None, set_as_global: bool = False):\nself._base_url = environ.get(\"YDATA_BASE_URL\", DEFAULT_URL)\nself._scheme = 'https'\nself._headers = {'Authorization': credentials}\nself._http_client = httpClient(\nheaders=self._headers, timeout=Timeout(10, read=None))\nself._handshake()\nself._project = project if project is not None else self._get_default_project(\ncredentials)\nself.project = project\nif set_as_global:\nself.__set_global()\ndef post(self, endpoint: str, data: Optional[Dict] = None, json: Optional[Dict] = None, files: Optional[Dict] = None, raise_for_status: bool = True) -&gt; Response:\n\"\"\"POST request to the backend.\n        Args:\n            endpoint (str): POST endpoint\n            data (Optional[dict]): (optional) multipart form data\n            json (Optional[dict]): (optional) json data\n            files (Optional[dict]): (optional) files to be sent\n            raise_for_status (bool): raise an exception on error\n        Returns:\n            Response object\n        \"\"\"\nurl_data = self.__build_url(endpoint, data=data, json=json, files=files)\nresponse = self._http_client.post(**url_data)\nif response.status_code != Client.codes.OK and raise_for_status:\nself.__raise_for_status(response)\nreturn response\ndef get(self, endpoint: str, params: Optional[Dict] = None, cookies: Optional[Dict] = None, raise_for_status: bool = True) -&gt; Response:\n\"\"\"GET request to the backend.\n        Args:\n            endpoint (str): GET endpoint\n            cookies (Optional[dict]): (optional) cookies data\n            raise_for_status (bool): raise an exception on error\n        Returns:\n            Response object\n        \"\"\"\nurl_data = self.__build_url(endpoint, params=params, cookies=cookies)\nresponse = self._http_client.get(**url_data)\nif response.status_code != Client.codes.OK and raise_for_status:\nself.__raise_for_status(response)\nreturn response\ndef get_static_file(self, endpoint: str, raise_for_status: bool = True) -&gt; Response:\n\"\"\"Retrieve a static file from the backend.\n        Args:\n            endpoint (str): GET endpoint\n            raise_for_status (bool): raise an exception on error\n        Returns:\n            Response object\n        \"\"\"\nurl_data = self.__build_url(endpoint)\nurl_data['url'] = f'{self._scheme}://{self._base_url}/static-content{endpoint}'\nresponse = self._http_client.get(**url_data)\nif response.status_code != Client.codes.OK and raise_for_status:\nself.__raise_for_status(response)\nreturn response\ndef _handshake(self):\n\"\"\"Client handshake.\n        It is used to determine is the client can connect with its\n        current authorization token.\n        \"\"\"\nresponse = self.get('/profiles', params={}, raise_for_status=False)\nif response.status_code == Client.codes.FOUND:\nparser = LinkExtractor()\nparser.feed(response.text)\nraise ClientHandshakeError(auth_link=parser.link)\ndef _get_default_project(self, token: str):\nresponse = self.get('/profiles/me', params={}, cookies={'access_token': token})\ndata: Dict = response.json()\nreturn data['myWorkspace']\ndef __build_url(self, endpoint: str, params: Optional[Dict] = None, data: Optional[Dict] = None, json: Optional[Dict] = None, files: Optional[Dict] = None, cookies: Optional[Dict] = None) -&gt; Dict:\n\"\"\"Build a request for the backend.\n        Args:\n            endpoint (str): backend endpoint\n            params (Optional[dict]): URL parameters\n            data (Optional[Project]): (optional) multipart form data\n            json (Optional[dict]): (optional) json data\n            files (Optional[dict]): (optional) files to be sent\n            cookies (Optional[dict]): (optional) cookies data\n        Returns:\n            dictionary containing the information to perform a request\n        \"\"\"\n_params = params if params is not None else {\n'ns': self._project\n}\nurl_data = {\n'url': f'{self._scheme}://{self._base_url}/api{endpoint}',\n'headers': self._headers,\n'params': _params,\n}\nif data is not None:\nurl_data['data'] = data\nif json is not None:\nurl_data['json'] = json\nif files is not None:\nurl_data['files'] = files\nif cookies is not None:\nurl_data['cookies'] = cookies\nreturn url_data\ndef __set_global(self) -&gt; None:\n\"\"\"Sets a client instance as global.\"\"\"\n# If the client is stateful, close it gracefully!\nClient.GLOBAL_CLIENT = self\ndef __raise_for_status(self, response: Response) -&gt; None:\n\"\"\"Raise an exception if the response is not OK.\n        When an exception is raised, we try to convert it to a ResponseError which is\n        a wrapper around a backend error. This usually gives enough context and provides\n        nice error message.\n        If it cannot be converted to ResponseError, it is re-raised.\n        Args:\n            response (Response): response to analyze\n        \"\"\"\ntry:\nresponse.raise_for_status()\nexcept HTTPStatusError as e:\nwith suppress(Exception):\ne = ResponseError(**response.json())\nraise e\n</code></pre>"},{"location":"reference/api/common/client/#ydata.sdk.common.client.client.Client.get","title":"<code>get(endpoint, params=None, cookies=None, raise_for_status=True)</code>","text":"<p>GET request to the backend.</p> <p>Parameters:</p> Name Type Description Default <code>endpoint</code> <code>str</code> <p>GET endpoint</p> required <code>cookies</code> <code>Optional[dict]</code> <p>(optional) cookies data</p> <code>None</code> <code>raise_for_status</code> <code>bool</code> <p>raise an exception on error</p> <code>True</code> <p>Returns:</p> Type Description <code>Response</code> <p>Response object</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/common/client/client.py</code> <pre><code>def get(self, endpoint: str, params: Optional[Dict] = None, cookies: Optional[Dict] = None, raise_for_status: bool = True) -&gt; Response:\n\"\"\"GET request to the backend.\n    Args:\n        endpoint (str): GET endpoint\n        cookies (Optional[dict]): (optional) cookies data\n        raise_for_status (bool): raise an exception on error\n    Returns:\n        Response object\n    \"\"\"\nurl_data = self.__build_url(endpoint, params=params, cookies=cookies)\nresponse = self._http_client.get(**url_data)\nif response.status_code != Client.codes.OK and raise_for_status:\nself.__raise_for_status(response)\nreturn response\n</code></pre>"},{"location":"reference/api/common/client/#ydata.sdk.common.client.client.Client.get_static_file","title":"<code>get_static_file(endpoint, raise_for_status=True)</code>","text":"<p>Retrieve a static file from the backend.</p> <p>Parameters:</p> Name Type Description Default <code>endpoint</code> <code>str</code> <p>GET endpoint</p> required <code>raise_for_status</code> <code>bool</code> <p>raise an exception on error</p> <code>True</code> <p>Returns:</p> Type Description <code>Response</code> <p>Response object</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/common/client/client.py</code> <pre><code>def get_static_file(self, endpoint: str, raise_for_status: bool = True) -&gt; Response:\n\"\"\"Retrieve a static file from the backend.\n    Args:\n        endpoint (str): GET endpoint\n        raise_for_status (bool): raise an exception on error\n    Returns:\n        Response object\n    \"\"\"\nurl_data = self.__build_url(endpoint)\nurl_data['url'] = f'{self._scheme}://{self._base_url}/static-content{endpoint}'\nresponse = self._http_client.get(**url_data)\nif response.status_code != Client.codes.OK and raise_for_status:\nself.__raise_for_status(response)\nreturn response\n</code></pre>"},{"location":"reference/api/common/client/#ydata.sdk.common.client.client.Client.post","title":"<code>post(endpoint, data=None, json=None, files=None, raise_for_status=True)</code>","text":"<p>POST request to the backend.</p> <p>Parameters:</p> Name Type Description Default <code>endpoint</code> <code>str</code> <p>POST endpoint</p> required <code>data</code> <code>Optional[dict]</code> <p>(optional) multipart form data</p> <code>None</code> <code>json</code> <code>Optional[dict]</code> <p>(optional) json data</p> <code>None</code> <code>files</code> <code>Optional[dict]</code> <p>(optional) files to be sent</p> <code>None</code> <code>raise_for_status</code> <code>bool</code> <p>raise an exception on error</p> <code>True</code> <p>Returns:</p> Type Description <code>Response</code> <p>Response object</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/common/client/client.py</code> <pre><code>def post(self, endpoint: str, data: Optional[Dict] = None, json: Optional[Dict] = None, files: Optional[Dict] = None, raise_for_status: bool = True) -&gt; Response:\n\"\"\"POST request to the backend.\n    Args:\n        endpoint (str): POST endpoint\n        data (Optional[dict]): (optional) multipart form data\n        json (Optional[dict]): (optional) json data\n        files (Optional[dict]): (optional) files to be sent\n        raise_for_status (bool): raise an exception on error\n    Returns:\n        Response object\n    \"\"\"\nurl_data = self.__build_url(endpoint, data=data, json=json, files=files)\nresponse = self._http_client.post(**url_data)\nif response.status_code != Client.codes.OK and raise_for_status:\nself.__raise_for_status(response)\nreturn response\n</code></pre>"},{"location":"reference/api/common/types/","title":"Types","text":""},{"location":"reference/api/connectors/connector/","title":"Connector","text":"<p>         Bases: <code>ModelFactoryMixin</code></p> <p>A <code>Connector</code> allows to connect and access data stored in various places. The list of available connectors can be found here.</p> <p>Parameters:</p> Name Type Description Default <code>connector_type</code> <code>Union[ConnectorType, str]</code> <p>Type of the connector to be created</p> <code>None</code> <code>credentials</code> <code>dict</code> <p>Connector credentials</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>(optional) Connector name</p> <code>None</code> <code>client</code> <code>Client</code> <p>(optional) Client to connect to the backend</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>uid</code> <code>UID</code> <p>UID fo the connector instance (creating internally)</p> <code>type</code> <code>ConnectorType</code> <p>Type of the connector</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/connectors/connector.py</code> <pre><code>class Connector(ModelFactoryMixin):\n\"\"\"A [`Connector`][ydata.sdk.connectors.Connector] allows to connect and\n    access data stored in various places. The list of available connectors can\n    be found [here][ydata.sdk.connectors.ConnectorType].\n    Arguments:\n        connector_type (Union[ConnectorType, str]): Type of the connector to be created\n        credentials (dict): Connector credentials\n        name (Optional[str]): (optional) Connector name\n        client (Client): (optional) Client to connect to the backend\n    Attributes:\n        uid (UID): UID fo the connector instance (creating internally)\n        type (ConnectorType): Type of the connector\n    \"\"\"\ndef __init__(self, connector_type: Union[ConnectorType, str] = None, credentials: Optional[Dict] = None,  name: Optional[str] = None, client: Optional[Client] = None):\nself._init_common(client=client)\nself._model: Optional[mConnector] = self._create_model(\nconnector_type, credentials, name, client=client)\n@init_client\ndef _init_common(self, client: Optional[Client] = None):\nself._client = client\nself._logger = create_logger(__name__, level=LOG_LEVEL)\n@property\ndef uid(self) -&gt; UID:\nreturn self._model.uid\n@property\ndef type(self) -&gt; str:\nreturn self._model.type\n@staticmethod\n@init_client\ndef get(uid: UID, client: Optional[Client] = None) -&gt; \"Connector\":\n\"\"\"Get an existing connector.\n        Arguments:\n            uid (UID): Connector identifier\n            client (Client): (optional) Client to connect to the backend\n        Returns:\n            Connector\n        \"\"\"\nconnectors: ConnectorsList = Connector.list(client=client)\ndata = connectors.get_by_uid(uid)\nmodel = mConnector(**data)\nconnector = ModelFactoryMixin._init_from_model_data(Connector, model)\nreturn connector\n@staticmethod\ndef _init_connector_type(connector_type: Union[ConnectorType, str]) -&gt; ConnectorType:\nif isinstance(connector_type, str):\ntry:\nconnector_type = ConnectorType(connector_type)\nexcept Exception:\nc_list = \", \".join([c.value for c in ConnectorType])\nraise InvalidConnectorError(\nf\"ConnectorType '{connector_type}' does not exist.\\nValid connector types are: {c_list}.\")\nreturn connector_type\n@staticmethod\ndef _init_credentials(connector_type: ConnectorType, credentials: Union[str, Path, Dict, Credentials]) -&gt; Credentials:\n_credentials = None\nif isinstance(credentials, str):\ncredentials = Path(credentials)\nif isinstance(credentials, Path):\ntry:\n_credentials = json_loads(credentials.open().read())\nexcept Exception:\nraise CredentialTypeError(\n'Could not read the credentials. Please, check your path or credentials structure.')\ntry:\nfrom ydata.sdk.connectors._models.connector_map import TYPE_TO_CLASS\ncredential_cls = TYPE_TO_CLASS.get(connector_type.value)\n_credentials = credential_cls(**_credentials)\nexcept Exception:\nraise CredentialTypeError(\n\"Could not create the credentials. Verify the path or the structure your credentials.\")\nreturn _credentials\n@staticmethod\ndef create(connector_type: Union[ConnectorType, str], credentials: Union[str, Path, Dict, Credentials], name: Optional[str] = None, client: Optional[Client] = None) -&gt; \"Connector\":\n\"\"\"Create a new connector.\n        Arguments:\n            connector_type (Union[ConnectorType, str]): Type of the connector to be created\n            credentials (dict): Connector credentials\n            name (Optional[str]): (optional) Connector name\n            client (Client): (optional) Client to connect to the backend\n        Returns:\n            New connector\n        \"\"\"\nmodel = Connector._create_model(\nconnector_type=connector_type, credentials=credentials, name=name, client=client)\nconnector = ModelFactoryMixin._init_from_model_data(\nConnector, model)\nreturn connector\n@classmethod\n@init_client\ndef _create_model(cls, connector_type: Union[ConnectorType, str], credentials: Union[str, Path, Dict, Credentials], name: Optional[str] = None, client: Optional[Client] = None) -&gt; mConnector:\n_name = name if name is not None else str(uuid4())\n_connector_type = Connector._init_connector_type(connector_type)\n_credentials = Connector._init_credentials(_connector_type, credentials)\npayload = {\n\"type\": _connector_type.value,\n\"credentials\": _credentials.dict(by_alias=True),\n\"name\": _name\n}\nresponse = client.post('/connector/', json=payload)\ndata: list = response.json()\nreturn mConnector(**data)\n@staticmethod\n@init_client\ndef list(client: Optional[Client] = None) -&gt; ConnectorsList:\n\"\"\"List the connectors instances.\n        Arguments:\n            client (Client): (optional) Client to connect to the backend\n        Returns:\n            List of connectors\n        \"\"\"\nresponse = client.get('/connector')\ndata: list = response.json()\nreturn ConnectorsList(data)\ndef __repr__(self):\nreturn self._model.__repr__()\n</code></pre>"},{"location":"reference/api/connectors/connector/#ydata.sdk.connectors.connector.Connector.create","title":"<code>create(connector_type, credentials, name=None, client=None)</code>  <code>staticmethod</code>","text":"<p>Create a new connector.</p> <p>Parameters:</p> Name Type Description Default <code>connector_type</code> <code>Union[ConnectorType, str]</code> <p>Type of the connector to be created</p> required <code>credentials</code> <code>dict</code> <p>Connector credentials</p> required <code>name</code> <code>Optional[str]</code> <p>(optional) Connector name</p> <code>None</code> <code>client</code> <code>Client</code> <p>(optional) Client to connect to the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>Connector</code> <p>New connector</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/connectors/connector.py</code> <pre><code>@staticmethod\ndef create(connector_type: Union[ConnectorType, str], credentials: Union[str, Path, Dict, Credentials], name: Optional[str] = None, client: Optional[Client] = None) -&gt; \"Connector\":\n\"\"\"Create a new connector.\n    Arguments:\n        connector_type (Union[ConnectorType, str]): Type of the connector to be created\n        credentials (dict): Connector credentials\n        name (Optional[str]): (optional) Connector name\n        client (Client): (optional) Client to connect to the backend\n    Returns:\n        New connector\n    \"\"\"\nmodel = Connector._create_model(\nconnector_type=connector_type, credentials=credentials, name=name, client=client)\nconnector = ModelFactoryMixin._init_from_model_data(\nConnector, model)\nreturn connector\n</code></pre>"},{"location":"reference/api/connectors/connector/#ydata.sdk.connectors.connector.Connector.get","title":"<code>get(uid, client=None)</code>  <code>staticmethod</code>","text":"<p>Get an existing connector.</p> <p>Parameters:</p> Name Type Description Default <code>uid</code> <code>UID</code> <p>Connector identifier</p> required <code>client</code> <code>Client</code> <p>(optional) Client to connect to the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>Connector</code> <p>Connector</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/connectors/connector.py</code> <pre><code>@staticmethod\n@init_client\ndef get(uid: UID, client: Optional[Client] = None) -&gt; \"Connector\":\n\"\"\"Get an existing connector.\n    Arguments:\n        uid (UID): Connector identifier\n        client (Client): (optional) Client to connect to the backend\n    Returns:\n        Connector\n    \"\"\"\nconnectors: ConnectorsList = Connector.list(client=client)\ndata = connectors.get_by_uid(uid)\nmodel = mConnector(**data)\nconnector = ModelFactoryMixin._init_from_model_data(Connector, model)\nreturn connector\n</code></pre>"},{"location":"reference/api/connectors/connector/#ydata.sdk.connectors.connector.Connector.list","title":"<code>list(client=None)</code>  <code>staticmethod</code>","text":"<p>List the connectors instances.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>Client</code> <p>(optional) Client to connect to the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>ConnectorsList</code> <p>List of connectors</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/connectors/connector.py</code> <pre><code>@staticmethod\n@init_client\ndef list(client: Optional[Client] = None) -&gt; ConnectorsList:\n\"\"\"List the connectors instances.\n    Arguments:\n        client (Client): (optional) Client to connect to the backend\n    Returns:\n        List of connectors\n    \"\"\"\nresponse = client.get('/connector')\ndata: list = response.json()\nreturn ConnectorsList(data)\n</code></pre>"},{"location":"reference/api/connectors/connector/#connectortype","title":"ConnectorType","text":"<p>         Bases: <code>Enum</code></p>"},{"location":"reference/api/connectors/connector/#ydata.sdk.connectors._models.connector_type.ConnectorType.AWS_S3","title":"<code>AWS_S3 = 'aws-s3'</code>  <code>class-attribute</code>","text":"<p>AWS S3 connector</p>"},{"location":"reference/api/connectors/connector/#ydata.sdk.connectors._models.connector_type.ConnectorType.AZURE_BLOB","title":"<code>AZURE_BLOB = 'azure-blob'</code>  <code>class-attribute</code>","text":"<p>Azure Blob connector</p>"},{"location":"reference/api/connectors/connector/#ydata.sdk.connectors._models.connector_type.ConnectorType.AZURE_SQL","title":"<code>AZURE_SQL = 'azure-sql'</code>  <code>class-attribute</code>","text":"<p>AzureSQL connector</p>"},{"location":"reference/api/connectors/connector/#ydata.sdk.connectors._models.connector_type.ConnectorType.BIGQUERY","title":"<code>BIGQUERY = 'google-bigquery'</code>  <code>class-attribute</code>","text":"<p>BigQuery connector</p>"},{"location":"reference/api/connectors/connector/#ydata.sdk.connectors._models.connector_type.ConnectorType.FILE","title":"<code>FILE = 'file'</code>  <code>class-attribute</code>","text":"<p>File connector (placeholder)</p>"},{"location":"reference/api/connectors/connector/#ydata.sdk.connectors._models.connector_type.ConnectorType.GCS","title":"<code>GCS = 'gcs'</code>  <code>class-attribute</code>","text":"<p>Google Cloud Storage connector</p>"},{"location":"reference/api/connectors/connector/#ydata.sdk.connectors._models.connector_type.ConnectorType.MYSQL","title":"<code>MYSQL = 'mysql'</code>  <code>class-attribute</code>","text":"<p>MySQL connector</p>"},{"location":"reference/api/connectors/connector/#ydata.sdk.connectors._models.connector_type.ConnectorType.SNOWFLAKE","title":"<code>SNOWFLAKE = 'snowflake'</code>  <code>class-attribute</code>","text":"<p>Snowflake connector</p>"},{"location":"reference/api/datasources/datasource/","title":"DataSource","text":"<p>         Bases: <code>ModelFactoryMixin</code></p> <p>A <code>DataSource</code> represents a dataset to be used by a Synthesizer as training data.</p> <p>Parameters:</p> Name Type Description Default <code>connector</code> <code>Connector</code> <p>Connector from which the datasource is created</p> required <code>datatype</code> <code>Optional[Union[DataSourceType, str]]</code> <p>(optional) DataSource type</p> <code>DataSourceType.TABULAR</code> <code>name</code> <code>Optional[str]</code> <p>(optional) DataSource name</p> <code>None</code> <code>wait_for_metadata</code> <code>bool</code> <p>If <code>True</code>, wait until the metadata is fully calculated</p> <code>True</code> <code>client</code> <code>Client</code> <p>(optional) Client to connect to the backend</p> <code>None</code> <code>**config</code> <p>Datasource specific configuration</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>uid</code> <code>UID</code> <p>UID fo the datasource instance</p> <code>datatype</code> <code>DataSourceType</code> <p>Data source type</p> <code>status</code> <code>Status</code> <p>Status of the datasource</p> <code>metadata</code> <code>Metadata</code> <p>Metadata associated to the datasource</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/datasources/datasource.py</code> <pre><code>class DataSource(ModelFactoryMixin):\n\"\"\"A [`DataSource`][ydata.sdk.datasources.DataSource] represents a dataset\n    to be used by a Synthesizer as training data.\n    Arguments:\n        connector (Connector): Connector from which the datasource is created\n        datatype (Optional[Union[DataSourceType, str]]): (optional) DataSource type\n        name (Optional[str]): (optional) DataSource name\n        wait_for_metadata (bool): If `True`, wait until the metadata is fully calculated\n        client (Client): (optional) Client to connect to the backend\n        **config: Datasource specific configuration\n    Attributes:\n        uid (UID): UID fo the datasource instance\n        datatype (DataSourceType): Data source type\n        status (Status): Status of the datasource\n        metadata (Metadata): Metadata associated to the datasource\n    \"\"\"\ndef __init__(self, connector: Connector, datatype: Optional[Union[DataSourceType, str]] = DataSourceType.TABULAR, name: Optional[str] = None, wait_for_metadata: bool = True, client: Optional[Client] = None, **config):\ndatasource_type = CONNECTOR_TO_DADASOURCE.get(connector.type)\nself._init_common(client=client)\nself._model: Optional[mDataSource] = self._create_model(\nconnector=connector, datasource_type=datasource_type, datatype=datatype, config=config, name=name, client=self._client)\nif wait_for_metadata:\nself._model = DataSource._wait_for_metadata(self)._model\n@init_client\ndef _init_common(self, client: Optional[Client] = None):\nself._client = client\nself._logger = create_logger(__name__, level=LOG_LEVEL)\n@property\ndef uid(self) -&gt; UID:\nreturn self._model.uid\n@property\ndef datatype(self) -&gt; DataSourceType:\nreturn self._model.datatype\n@property\ndef status(self) -&gt; Status:\ntry:\nself._model = self.get(self._model.uid, self._client)._model\nreturn self._model.status\nexcept Exception:  # noqa: PIE786\nreturn Status.UNKNOWN\n@property\ndef metadata(self) -&gt; Metadata:\nreturn self._model.metadata\n@staticmethod\n@init_client\ndef list(client: Optional[Client] = None) -&gt; DataSourceList:\n\"\"\"List the  [`DataSource`][ydata.sdk.datasources.DataSource]\n        instances.\n        Arguments:\n            client (Client): (optional) Client to connect to the backend\n        Returns:\n            List of datasources\n        \"\"\"\ndef __process_data(data: list) -&gt; list:\nto_del = ['metadata']\nfor e in data:\nfor k in to_del:\ne.pop(k, None)\nreturn data\nresponse = client.get('/datasource')\ndata: list = response.json()\ndata = __process_data(data)\nreturn DataSourceList(data)\n@staticmethod\n@init_client\ndef get(uid: UID, client: Optional[Client] = None) -&gt; \"DataSource\":\n\"\"\"Get an existing [`DataSource`][ydata.sdk.datasources.DataSource].\n        Arguments:\n            uid (UID): DataSource identifier\n            client (Client): (optional) Client to connect to the backend\n        Returns:\n            DataSource\n        \"\"\"\nresponse = client.get(f'/datasource/{uid}')\ndata: list = response.json()\ndatasource_type = CONNECTOR_TO_DADASOURCE.get(\nConnectorType(data['connector']['type']))\nmodel = DataSource._model_from_api(data, datasource_type)\ndatasource = ModelFactoryMixin._init_from_model_data(DataSource, model)\nreturn datasource\n@classmethod\ndef create(cls, connector: Connector, datatype: Optional[Union[DataSourceType, str]] = DataSourceType.TABULAR, name: Optional[str] = None, wait_for_metadata: bool = True, client: Optional[Client] = None, **config) -&gt; \"DataSource\":\n\"\"\"Create a new [`DataSource`][ydata.sdk.datasources.DataSource].\n        Arguments:\n            connector (Connector): Connector from which the datasource is created\n            datatype (Optional[Union[DataSourceType, str]]): (optional) DataSource type\n            name (Optional[str]): (optional) DataSource name\n            wait_for_metadata (bool): If `True`, wait until the metadata is fully calculated\n            client (Client): (optional) Client to connect to the backend\n            **config: Datasource specific configuration\n        Returns:\n            DataSource\n        \"\"\"\ndatasource_type = CONNECTOR_TO_DADASOURCE.get(connector.type)\nreturn cls._create(connector=connector, datasource_type=datasource_type, datatype=datatype, config=config, name=name, wait_for_metadata=wait_for_metadata, client=client)\n@classmethod\ndef _create(cls, connector: Connector, datasource_type: Type[mDataSource], datatype: Optional[Union[DataSourceType, str]] = DataSourceType.TABULAR, config: Optional[Dict] = None, name: Optional[str] = None, wait_for_metadata: bool = True, client: Optional[Client] = None) -&gt; \"DataSource\":\nmodel = DataSource._create_model(\nconnector, datasource_type, datatype, config, name, client)\ndatasource = ModelFactoryMixin._init_from_model_data(DataSource, model)\nif wait_for_metadata:\ndatasource._model = DataSource._wait_for_metadata(datasource)._model\nreturn datasource\n@classmethod\n@init_client\ndef _create_model(cls, connector: Connector, datasource_type: Type[mDataSource], datatype: Optional[Union[DataSourceType, str]] = DataSourceType.TABULAR, config: Optional[Dict] = None, name: Optional[str] = None, client: Optional[Client] = None) -&gt; mDataSource:\n_name = name if name is not None else str(uuid4())\n_config = config if config is not None else {}\npayload = {\n\"name\": _name,\n\"connector\": {\n\"uid\": connector.uid,\n\"type\": connector.type.value\n},\n\"dataType\": datatype.value\n}\nif connector.type != ConnectorType.FILE:\n_config = datasource_type(**config).to_payload()\npayload.update(_config)\nresponse = client.post('/datasource/', json=payload)\ndata: list = response.json()\nreturn DataSource._model_from_api(data, datasource_type)\n@staticmethod\ndef _wait_for_metadata(datasource):\nlogger = create_logger(__name__, level=LOG_LEVEL)\nwhile datasource.status not in [Status.AVAILABLE, Status.FAILED, Status.UNAVAILABLE]:\nlogger.info(f'Calculating metadata [{datasource.status}]')\ndatasource = DataSource.get(uid=datasource.uid, client=datasource._client)\nsleep(BACKOFF)\nreturn datasource\n@staticmethod\ndef _resolve_api_status(api_status: Dict) -&gt; Status:\nstatus = Status(api_status.get('state', Status.UNKNOWN.name))\nvalidation = ValidationState(api_status.get('validation', {}).get(\n'state', ValidationState.UNKNOWN.name))\nif validation == ValidationState.FAILED:\nstatus = Status.FAILED\nreturn status\n@staticmethod\ndef _model_from_api(data: Dict, datasource_type: Type[mDataSource]) -&gt; mDataSource:\ndata['datatype'] = data.pop('dataType')\ndata['state'] = data['status']\ndata['status'] = DataSource._resolve_api_status(data['status'])\ndata = filter_dict(datasource_type, data)\nmodel = datasource_type(**data)\nreturn model\ndef __repr__(self):\nreturn self._model.__repr__()\n</code></pre>"},{"location":"reference/api/datasources/datasource/#ydata.sdk.datasources.datasource.DataSource.create","title":"<code>create(connector, datatype=DataSourceType.TABULAR, name=None, wait_for_metadata=True, client=None, **config)</code>  <code>classmethod</code>","text":"<p>Create a new <code>DataSource</code>.</p> <p>Parameters:</p> Name Type Description Default <code>connector</code> <code>Connector</code> <p>Connector from which the datasource is created</p> required <code>datatype</code> <code>Optional[Union[DataSourceType, str]]</code> <p>(optional) DataSource type</p> <code>DataSourceType.TABULAR</code> <code>name</code> <code>Optional[str]</code> <p>(optional) DataSource name</p> <code>None</code> <code>wait_for_metadata</code> <code>bool</code> <p>If <code>True</code>, wait until the metadata is fully calculated</p> <code>True</code> <code>client</code> <code>Client</code> <p>(optional) Client to connect to the backend</p> <code>None</code> <code>**config</code> <p>Datasource specific configuration</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataSource</code> <p>DataSource</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/datasources/datasource.py</code> <pre><code>@classmethod\ndef create(cls, connector: Connector, datatype: Optional[Union[DataSourceType, str]] = DataSourceType.TABULAR, name: Optional[str] = None, wait_for_metadata: bool = True, client: Optional[Client] = None, **config) -&gt; \"DataSource\":\n\"\"\"Create a new [`DataSource`][ydata.sdk.datasources.DataSource].\n    Arguments:\n        connector (Connector): Connector from which the datasource is created\n        datatype (Optional[Union[DataSourceType, str]]): (optional) DataSource type\n        name (Optional[str]): (optional) DataSource name\n        wait_for_metadata (bool): If `True`, wait until the metadata is fully calculated\n        client (Client): (optional) Client to connect to the backend\n        **config: Datasource specific configuration\n    Returns:\n        DataSource\n    \"\"\"\ndatasource_type = CONNECTOR_TO_DADASOURCE.get(connector.type)\nreturn cls._create(connector=connector, datasource_type=datasource_type, datatype=datatype, config=config, name=name, wait_for_metadata=wait_for_metadata, client=client)\n</code></pre>"},{"location":"reference/api/datasources/datasource/#ydata.sdk.datasources.datasource.DataSource.get","title":"<code>get(uid, client=None)</code>  <code>staticmethod</code>","text":"<p>Get an existing <code>DataSource</code>.</p> <p>Parameters:</p> Name Type Description Default <code>uid</code> <code>UID</code> <p>DataSource identifier</p> required <code>client</code> <code>Client</code> <p>(optional) Client to connect to the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>DataSource</code> <p>DataSource</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/datasources/datasource.py</code> <pre><code>@staticmethod\n@init_client\ndef get(uid: UID, client: Optional[Client] = None) -&gt; \"DataSource\":\n\"\"\"Get an existing [`DataSource`][ydata.sdk.datasources.DataSource].\n    Arguments:\n        uid (UID): DataSource identifier\n        client (Client): (optional) Client to connect to the backend\n    Returns:\n        DataSource\n    \"\"\"\nresponse = client.get(f'/datasource/{uid}')\ndata: list = response.json()\ndatasource_type = CONNECTOR_TO_DADASOURCE.get(\nConnectorType(data['connector']['type']))\nmodel = DataSource._model_from_api(data, datasource_type)\ndatasource = ModelFactoryMixin._init_from_model_data(DataSource, model)\nreturn datasource\n</code></pre>"},{"location":"reference/api/datasources/datasource/#ydata.sdk.datasources.datasource.DataSource.list","title":"<code>list(client=None)</code>  <code>staticmethod</code>","text":"<p>List the  <code>DataSource</code> instances.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>Client</code> <p>(optional) Client to connect to the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>DataSourceList</code> <p>List of datasources</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/datasources/datasource.py</code> <pre><code>@staticmethod\n@init_client\ndef list(client: Optional[Client] = None) -&gt; DataSourceList:\n\"\"\"List the  [`DataSource`][ydata.sdk.datasources.DataSource]\n    instances.\n    Arguments:\n        client (Client): (optional) Client to connect to the backend\n    Returns:\n        List of datasources\n    \"\"\"\ndef __process_data(data: list) -&gt; list:\nto_del = ['metadata']\nfor e in data:\nfor k in to_del:\ne.pop(k, None)\nreturn data\nresponse = client.get('/datasource')\ndata: list = response.json()\ndata = __process_data(data)\nreturn DataSourceList(data)\n</code></pre>"},{"location":"reference/api/datasources/datasource/#status","title":"Status","text":"<p>         Bases: <code>StringEnum</code></p> <p>Represent the status of a <code>DataSource</code>.</p>"},{"location":"reference/api/datasources/datasource/#ydata.sdk.datasources._models.status.Status.AVAILABLE","title":"<code>AVAILABLE = 'available'</code>  <code>class-attribute</code>","text":"<p>The <code>DataSource</code> is available and ready to be used.</p>"},{"location":"reference/api/datasources/datasource/#ydata.sdk.datasources._models.status.Status.DELETED","title":"<code>DELETED = 'deleted'</code>  <code>class-attribute</code>","text":"<p>The <code>DataSource</code> is to be deleted or has been deleted.</p>"},{"location":"reference/api/datasources/datasource/#ydata.sdk.datasources._models.status.Status.FAILED","title":"<code>FAILED = 'failed'</code>  <code>class-attribute</code>","text":"<p>The <code>DataSource</code> preparation or validation has failed.</p>"},{"location":"reference/api/datasources/datasource/#ydata.sdk.datasources._models.status.Status.PREPARING","title":"<code>PREPARING = 'preparing'</code>  <code>class-attribute</code>","text":"<p>The <code>DataSource</code> is being prepared.</p>"},{"location":"reference/api/datasources/datasource/#ydata.sdk.datasources._models.status.Status.UNAVAILABLE","title":"<code>UNAVAILABLE = 'unavailable'</code>  <code>class-attribute</code>","text":"<p>The <code>DataSource</code> is unavailable at the moment.</p>"},{"location":"reference/api/datasources/datasource/#ydata.sdk.datasources._models.status.Status.UNKNOWN","title":"<code>UNKNOWN = 'unknown'</code>  <code>class-attribute</code>","text":"<p>The <code>DataSource</code> status could not be retrieved.</p>"},{"location":"reference/api/datasources/datasource/#ydata.sdk.datasources._models.status.Status.VALIDATING","title":"<code>VALIDATING = 'validating'</code>  <code>class-attribute</code>","text":"<p>The <code>DataSource</code> is being validated.</p>"},{"location":"reference/api/datasources/datasource/#datasourcetype","title":"DataSourceType","text":"<p>         Bases: <code>StringEnum</code></p>"},{"location":"reference/api/datasources/datasource/#ydata.sdk.datasources._models.datatype.DataSourceType.TABULAR","title":"<code>TABULAR = 'tabular'</code>  <code>class-attribute</code>","text":"<p>The <code>DataSource</code> is tabular (i.e. it does not have a temporal dimension).</p>"},{"location":"reference/api/datasources/datasource/#ydata.sdk.datasources._models.datatype.DataSourceType.TIMESERIES","title":"<code>TIMESERIES = 'timeseries'</code>  <code>class-attribute</code>","text":"<p>The <code>DataSource</code> has a temporal dimension.</p>"},{"location":"reference/api/datasources/metadata/","title":"Metadata","text":"<p>         Bases: <code>BaseModel</code></p> <p>The Metadata object contains descriptive information about a.</p> <p><code>DataSource</code></p> <p>Attributes:</p> Name Type Description <code>columns</code> <code>List[Column]</code> <p>columns information</p>"},{"location":"reference/api/synthesizers/base/","title":"Synthesizer","text":"<p>         Bases: <code>ABC</code>, <code>ModelFactoryMixin</code></p> <p>Main synthesizer class.</p> <p>This class cannot be directly instanciated because of the specificities between <code>RegularSynthesizer</code> and <code>TimeSeriesSynthesizer</code> <code>sample</code> methods.</p>"},{"location":"reference/api/synthesizers/base/#ydata.sdk.synthesizers.synthesizer.BaseSynthesizer--methods","title":"Methods","text":"<ul> <li><code>fit</code>: train a synthesizer instance.</li> <li><code>sample</code>: request synthetic data.</li> <li><code>status</code>: current status of the synthesizer instance.</li> </ul> Note <p>The synthesizer instance is created in the backend only when the <code>fit</code> method is called.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>Client</code> <p>(optional) Client to connect to the backend</p> <code>None</code> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/synthesizers/synthesizer.py</code> <pre><code>@typechecked\nclass BaseSynthesizer(ABC, ModelFactoryMixin):\n\"\"\"Main synthesizer class.\n    This class cannot be directly instanciated because of the specificities between [`RegularSynthesizer`][ydata.sdk.synthesizers.RegularSynthesizer] and [`TimeSeriesSynthesizer`][ydata.sdk.synthesizers.TimeSeriesSynthesizer] `sample` methods.\n    Methods\n    -------\n    - `fit`: train a synthesizer instance.\n    - `sample`: request synthetic data.\n    - `status`: current status of the synthesizer instance.\n    Note:\n            The synthesizer instance is created in the backend only when the `fit` method is called.\n    Arguments:\n        client (Client): (optional) Client to connect to the backend\n    \"\"\"\ndef __init__(self, client: Optional[Client] = None):\nself._init_common(client=client)\nself._model: Optional[mSynthesizer] = None\n@init_client\ndef _init_common(self, client: Optional[Client] = None):\nself._client = client\nself._logger = create_logger(__name__, level=LOG_LEVEL)\ndef fit(self, X: Union[DataSource, pdDataFrame],\nprivacy_level: PrivacyLevel = PrivacyLevel.HIGH_FIDELITY,\ndatatype: Optional[Union[DataSourceType, str]] = None,\nsortbykey: Optional[Union[str, List[str]]] = None,\nentity_id_cols: Optional[Union[str, List[str]]] = None,\ngenerate_cols: Optional[List[str]] = None,\nexclude_cols: Optional[List[str]] = None,\ndtypes: Optional[Dict[str, Union[str, DataType]]] = None,\ntarget: Optional[str] = None,\nname: Optional[str] = None,\nanonymize: Optional[dict] = None) -&gt; None:\n\"\"\"Fit the synthesizer.\n        The synthesizer accepts as training dataset either a pandas [`DataFrame`][pandas.DataFrame] directly or a YData [`DataSource`][ydata.sdk.datasources.DataSource].\n        When the training dataset is a pandas [`DataFrame`][pandas.DataFrame], the argument `datatype` is required as it cannot be deduced.\n        The argument`sortbykey` is mandatory for [`TimeSeries`][ydata.sdk.datasources.DataSourceType.TIMESERIES].\n        By default, if `generate_cols` or `exclude_cols` are not specified, all columns are generated by the synthesizer.\n        The argument `exclude_cols` has precedence over `generate_cols`, i.e. a column `col` will not be generated if it is in both list.\n        Arguments:\n            X (Union[DataSource, pandas.DataFrame]): Training dataset\n            privacy_level (PrivacyLevel): Synthesizer privacy level (defaults to high fidelity)\n            datatype (Optional[Union[DataSourceType, str]]): (optional) Dataset datatype - required if `X` is a [`pandas.DataFrame`][pandas.DataFrame]\n            sortbykey (Union[str, List[str]]): (optional) column(s) to use to sort timeseries datasets\n            entity_id_cols (Union[str, List[str]]): (optional) columns representing entities ID\n            generate_cols (List[str]): (optional) columns that should be synthesized\n            exclude_cols (List[str]): (optional) columns that should not be synthesized\n            dtypes (Dict[str, Union[str, DataType]]): (optional) datatype mapping that will overwrite the datasource metadata column datatypes\n            target (Optional[str]): (optional) Target for the dataset\n            name (Optional[str]): (optional) Synthesizer instance name\n            anonymize (Optional[str]): (optional) fields to anonymize and the anonymization strategy\n        \"\"\"\nif self._is_initialized():\nraise AlreadyFittedError()\n_datatype = DataSourceType(datatype) if isinstance(\nX, pdDataFrame) else DataSourceType(X.datatype)\ndataset_attrs = self._init_datasource_attributes(\nsortbykey, entity_id_cols, generate_cols, exclude_cols, dtypes)\nself._validate_datasource_attributes(X, dataset_attrs, _datatype, target)\n# If the training data is a pandas dataframe, we first need to create a data source and then the instance\nif isinstance(X, pdDataFrame):\nif X.empty:\nraise EmptyDataError(\"The DataFrame is empty\")\n_X = LocalDataSource(source=X, datatype=_datatype, client=self._client)\nelse:\nif datatype != _datatype:\nwarn(\"When the training data is a DataSource, the argument `datatype` is ignored.\",\nDataSourceTypeWarning)\n_X = X\nif _X.status != dsStatus.AVAILABLE:\nraise DataSourceNotAvailableError(\nf\"The datasource '{_X.uid}' is not available (status = {_X.status.value})\")\nif isinstance(dataset_attrs, dict):\ndataset_attrs = DataSourceAttrs(**dataset_attrs)\nself._fit_from_datasource(\nX=_X, dataset_attrs=dataset_attrs, target=target, name=name, anonymize=anonymize, privacy_level=privacy_level)\n@staticmethod\ndef _init_datasource_attributes(\nsortbykey: Optional[Union[str, List[str]]],\nentity_id_cols: Optional[Union[str, List[str]]],\ngenerate_cols: Optional[List[str]],\nexclude_cols: Optional[List[str]],\ndtypes: Optional[Dict[str, Union[str, DataType]]]) -&gt; DataSourceAttrs:\ndataset_attrs = {\n'sortbykey': sortbykey if sortbykey is not None else [],\n'entity_id_cols': entity_id_cols if entity_id_cols is not None else [],\n'generate_cols': generate_cols if generate_cols is not None else [],\n'exclude_cols': exclude_cols if exclude_cols is not None else [],\n'dtypes': {k: DataType(v) for k, v in dtypes.items()} if dtypes is not None else {}\n}\nreturn DataSourceAttrs(**dataset_attrs)\n@staticmethod\ndef _validate_datasource_attributes(X: Union[DataSource, pdDataFrame], dataset_attrs: DataSourceAttrs, datatype: DataSourceType, target: Optional[str]):\ncolumns = []\nif isinstance(X, pdDataFrame):\ncolumns = X.columns\nif datatype is None:\nraise DataTypeMissingError(\n\"Argument `datatype` is mandatory for pandas.DataFrame training data\")\ndatatype = DataSourceType(datatype)\nelse:\ncolumns = [c.name for c in X.metadata.columns]\nif target is not None and target not in columns:\nraise DataSourceAttrsError(\n\"Invalid target: column '{target}' does not exist\")\nif datatype == DataSourceType.TIMESERIES:\nif not dataset_attrs.sortbykey:\nraise DataSourceAttrsError(\n\"The argument `sortbykey` is mandatory for timeseries datasource.\")\ninvalid_fields = {}\nfor field, v in dataset_attrs.dict().items():\nfield_columns = v if field != 'dtypes' else v.keys()\nnot_in_cols = [c for c in field_columns if c not in columns]\nif len(not_in_cols) &gt; 0:\ninvalid_fields[field] = not_in_cols\nif len(invalid_fields) &gt; 0:\nerror_msgs = [\"\\t- Field '{}': columns {} do not exist\".format(\nf, ', '.join(v)) for f, v in invalid_fields.items()]\nraise DataSourceAttrsError(\n\"The dataset attributes are invalid:\\n {}\".format('\\n'.join(error_msgs)))\n@staticmethod\ndef _metadata_to_payload(datatype: DataSourceType, ds_metadata: Metadata, dataset_attrs: Optional[DataSourceAttrs] = None) -&gt; list:\n\"\"\"Transform a the metadata and dataset attributes into a valid\n        payload.\n        Arguments:\n            datatype (DataSourceType): datasource type\n            ds_metadata (Metadata): datasource metadata object\n            dataset_attrs ( Optional[DataSourceAttrs] ): (optional) Dataset attributes\n        Returns:\n            payload dictionary\n        \"\"\"\ncolumns = {}\nfor c in ds_metadata.columns:\ncolumns[c.name] = {\n'name': c.name,\n'generation': True,\n'dataType': c.datatype if c.datatype != DataType.STR.value else DataType.CATEGORICAL.value,\n'varType': c.vartype,\n'entity': False,\n}\nif dataset_attrs is not None:\nif datatype == DataSourceType.TIMESERIES:\nfor c in ds_metadata.columns:\ncolumns[c.name]['sortBy'] = c.name in dataset_attrs.sortbykey\nfor c in dataset_attrs.entity_id_cols:\ncolumns[c]['entity'] = True\nfor c in dataset_attrs.generate_cols:\ncolumns[c]['generation'] = True\nfor c in dataset_attrs.exclude_cols:\ncolumns[c]['generation'] = False\n# Update metadata based on the datatypes and vartypes provided by the user\nfor k, v in dataset_attrs.dtypes.items():\nif k in columns and columns[k]['generation']:\ncolumns[k]['dataType'] = v.value\nreturn list(columns.values())\ndef _fit_from_datasource(\nself,\nX: DataSource,\nprivacy_level: PrivacyLevel = PrivacyLevel.HIGH_FIDELITY,\ndataset_attrs: Optional[DataSourceAttrs] = None,\ntarget: Optional[str] = None,\nname: Optional[str] = None,\nanonymize: Optional[dict] = None\n) -&gt; None:\n_name = name if name is not None else str(uuid4())\ncolumns = self._metadata_to_payload(\nDataSourceType(X.datatype), X.metadata, dataset_attrs)\npayload = {\n'name': _name,\n'dataSourceUID': X.uid,\n'metadata': {\n'dataType': X.datatype,\n\"columns\": columns,\n},\n'extraData': {\n'privacy_level': privacy_level.value\n}\n}\nif anonymize is not None:\npayload[\"extraData\"][\"anonymize\"] = anonymize\nif target is not None:\npayload['metadata']['target'] = target\nresponse = self._client.post('/synthesizer/', json=payload)\ndata: list = response.json()\nself._model, _ = self._model_from_api(X.datatype, data)\nwhile self.status not in [Status.READY, Status.FAILED]:\nself._logger.info('Training the synthesizer...')\nsleep(BACKOFF)\nif self.status == Status.FAILED:\nraise FittingError('Could not train the synthesizer')\n@staticmethod\ndef _model_from_api(datatype: str, data: Dict) -&gt; Tuple[mSynthesizer, Type[\"BaseSynthesizer\"]]:\nfrom ydata.sdk.synthesizers._models.synthesizer_map import TYPE_TO_CLASS\nsynth_cls = TYPE_TO_CLASS.get(SynthesizerType(datatype).value)\ndata['status'] = synth_cls._resolve_api_status(data['status'])\ndata = filter_dict(mSynthesizer, data)\nreturn mSynthesizer(**data), synth_cls\n@abstractmethod\ndef sample(self) -&gt; pdDataFrame:\n\"\"\"Abstract method to sample from a synthesizer.\"\"\"\ndef _sample(self, payload: Dict) -&gt; pdDataFrame:\n\"\"\"Sample from a synthesizer.\n        Arguments:\n            payload (dict): payload configuring the sample request\n        Returns:\n            pandas `DataFrame`\n        \"\"\"\nresponse = self._client.post(\nf\"/synthesizer/{self.uid}/sample\", json=payload)\ndata: Dict = response.json()\nsample_uid = data.get('uid')\nsample_status = None\nwhile sample_status not in ['finished', 'failed']:\nself._logger.info('Sampling from the synthesizer...')\nresponse = self._client.get(f'/synthesizer/{self.uid}/history')\nhistory: Dict = response.json()\nsample_data = next((s for s in history if s.get('uid') == sample_uid), None)\nsample_status = sample_data.get('status', {}).get('state')\nsleep(BACKOFF)\nresponse = self._client.get_static_file(\nf'/synthesizer/{self.uid}/sample/{sample_uid}/sample.csv')\ndata = StringIO(response.content.decode())\nreturn read_csv(data)\n@property\ndef uid(self) -&gt; UID:\n\"\"\"Get the status of a synthesizer instance.\n        Returns:\n            Synthesizer status\n        \"\"\"\nif not self._is_initialized():\nreturn Status.NOT_INITIALIZED\nreturn self._model.uid\n@property\ndef status(self) -&gt; Status:\n\"\"\"Get the status of a synthesizer instance.\n        Returns:\n            Synthesizer status\n        \"\"\"\nif not self._is_initialized():\nreturn Status.NOT_INITIALIZED\ntry:\nself = self.get(self._model.uid, self._client)\nreturn self._model.status\nexcept Exception:  # noqa: PIE786\nreturn Status.UNKNOWN\n@staticmethod\n@init_client\ndef get(uid: str, client: Optional[Client] = None) -&gt; \"BaseSynthesizer\":\n\"\"\"List the synthesizer instances.\n        Arguments:\n            uid (str): synthesizer instance uid\n            client (Client): (optional) Client to connect to the backend\n        Returns:\n            Synthesizer instance\n        \"\"\"\nresponse = client.get(f'/synthesizer/{uid}')\ndata: list = response.json()\nmodel, synth_cls = BaseSynthesizer._model_from_api(\ndata['dataSource']['dataType'], data)\nreturn ModelFactoryMixin._init_from_model_data(synth_cls, model)\n@staticmethod\n@init_client\ndef list(client: Optional[Client] = None) -&gt; SynthesizersList:\n\"\"\"List the synthesizer instances.\n        Arguments:\n            client (Client): (optional) Client to connect to the backend\n        Returns:\n            List of synthesizers\n        \"\"\"\ndef __process_data(data: list) -&gt; list:\nto_del = ['metadata', 'report', 'mode']\nfor e in data:\nfor k in to_del:\ne.pop(k, None)\nreturn data\nresponse = client.get('/synthesizer')\ndata: list = response.json()\ndata = __process_data(data)\nreturn SynthesizersList(data)\ndef _is_initialized(self) -&gt; bool:\n\"\"\"Determine if a synthesizer is instanciated or not.\n        Returns:\n            True if the synthesizer is instanciated\n        \"\"\"\nreturn self._model is not None\n@staticmethod\ndef _resolve_api_status(api_status: Dict) -&gt; Status:\n\"\"\"Determine the status of the Synthesizer.\n        The status of the synthesizer instance is determined by the state of\n        its different components.\n        Arguments:\n            api_status (dict): json from the endpoint GET /synthesizer\n        Returns:\n            Synthesizer Status\n        \"\"\"\nstatus = Status(api_status.get('state', Status.UNKNOWN.name))\nif status == Status.PREPARE:\nif PrepareState(api_status.get('prepare', {}).get(\n'state', PrepareState.UNKNOWN.name)) == PrepareState.FAILED:\nreturn Status.FAILED\nelif status == Status.TRAIN:\nif TrainingState(api_status.get('training', {}).get(\n'state', TrainingState.UNKNOWN.name)) == TrainingState.FAILED:\nreturn Status.FAILED\nelif status == Status.REPORT:\nif ReportState(api_status.get('report', {}).get(\n'state', ReportState.UNKNOWN.name)) == ReportState.FAILED:\nreturn Status.FAILED\nreturn status\n</code></pre>"},{"location":"reference/api/synthesizers/base/#ydata.sdk.synthesizers.synthesizer.BaseSynthesizer.status","title":"<code>status: Status</code>  <code>property</code>","text":"<p>Get the status of a synthesizer instance.</p> <p>Returns:</p> Type Description <code>Status</code> <p>Synthesizer status</p>"},{"location":"reference/api/synthesizers/base/#ydata.sdk.synthesizers.synthesizer.BaseSynthesizer.uid","title":"<code>uid: UID</code>  <code>property</code>","text":"<p>Get the status of a synthesizer instance.</p> <p>Returns:</p> Type Description <code>UID</code> <p>Synthesizer status</p>"},{"location":"reference/api/synthesizers/base/#ydata.sdk.synthesizers.synthesizer.BaseSynthesizer.fit","title":"<code>fit(X, privacy_level=PrivacyLevel.HIGH_FIDELITY, datatype=None, sortbykey=None, entity_id_cols=None, generate_cols=None, exclude_cols=None, dtypes=None, target=None, name=None, anonymize=None)</code>","text":"<p>Fit the synthesizer.</p> <p>The synthesizer accepts as training dataset either a pandas <code>DataFrame</code> directly or a YData <code>DataSource</code>. When the training dataset is a pandas <code>DataFrame</code>, the argument <code>datatype</code> is required as it cannot be deduced.</p> <p>The argument<code>sortbykey</code> is mandatory for <code>TimeSeries</code>.</p> <p>By default, if <code>generate_cols</code> or <code>exclude_cols</code> are not specified, all columns are generated by the synthesizer. The argument <code>exclude_cols</code> has precedence over <code>generate_cols</code>, i.e. a column <code>col</code> will not be generated if it is in both list.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[DataSource, pandas.DataFrame]</code> <p>Training dataset</p> required <code>privacy_level</code> <code>PrivacyLevel</code> <p>Synthesizer privacy level (defaults to high fidelity)</p> <code>PrivacyLevel.HIGH_FIDELITY</code> <code>datatype</code> <code>Optional[Union[DataSourceType, str]]</code> <p>(optional) Dataset datatype - required if <code>X</code> is a <code>pandas.DataFrame</code></p> <code>None</code> <code>sortbykey</code> <code>Union[str, List[str]]</code> <p>(optional) column(s) to use to sort timeseries datasets</p> <code>None</code> <code>entity_id_cols</code> <code>Union[str, List[str]]</code> <p>(optional) columns representing entities ID</p> <code>None</code> <code>generate_cols</code> <code>List[str]</code> <p>(optional) columns that should be synthesized</p> <code>None</code> <code>exclude_cols</code> <code>List[str]</code> <p>(optional) columns that should not be synthesized</p> <code>None</code> <code>dtypes</code> <code>Dict[str, Union[str, DataType]]</code> <p>(optional) datatype mapping that will overwrite the datasource metadata column datatypes</p> <code>None</code> <code>target</code> <code>Optional[str]</code> <p>(optional) Target for the dataset</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>(optional) Synthesizer instance name</p> <code>None</code> <code>anonymize</code> <code>Optional[str]</code> <p>(optional) fields to anonymize and the anonymization strategy</p> <code>None</code> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/synthesizers/synthesizer.py</code> <pre><code>def fit(self, X: Union[DataSource, pdDataFrame],\nprivacy_level: PrivacyLevel = PrivacyLevel.HIGH_FIDELITY,\ndatatype: Optional[Union[DataSourceType, str]] = None,\nsortbykey: Optional[Union[str, List[str]]] = None,\nentity_id_cols: Optional[Union[str, List[str]]] = None,\ngenerate_cols: Optional[List[str]] = None,\nexclude_cols: Optional[List[str]] = None,\ndtypes: Optional[Dict[str, Union[str, DataType]]] = None,\ntarget: Optional[str] = None,\nname: Optional[str] = None,\nanonymize: Optional[dict] = None) -&gt; None:\n\"\"\"Fit the synthesizer.\n    The synthesizer accepts as training dataset either a pandas [`DataFrame`][pandas.DataFrame] directly or a YData [`DataSource`][ydata.sdk.datasources.DataSource].\n    When the training dataset is a pandas [`DataFrame`][pandas.DataFrame], the argument `datatype` is required as it cannot be deduced.\n    The argument`sortbykey` is mandatory for [`TimeSeries`][ydata.sdk.datasources.DataSourceType.TIMESERIES].\n    By default, if `generate_cols` or `exclude_cols` are not specified, all columns are generated by the synthesizer.\n    The argument `exclude_cols` has precedence over `generate_cols`, i.e. a column `col` will not be generated if it is in both list.\n    Arguments:\n        X (Union[DataSource, pandas.DataFrame]): Training dataset\n        privacy_level (PrivacyLevel): Synthesizer privacy level (defaults to high fidelity)\n        datatype (Optional[Union[DataSourceType, str]]): (optional) Dataset datatype - required if `X` is a [`pandas.DataFrame`][pandas.DataFrame]\n        sortbykey (Union[str, List[str]]): (optional) column(s) to use to sort timeseries datasets\n        entity_id_cols (Union[str, List[str]]): (optional) columns representing entities ID\n        generate_cols (List[str]): (optional) columns that should be synthesized\n        exclude_cols (List[str]): (optional) columns that should not be synthesized\n        dtypes (Dict[str, Union[str, DataType]]): (optional) datatype mapping that will overwrite the datasource metadata column datatypes\n        target (Optional[str]): (optional) Target for the dataset\n        name (Optional[str]): (optional) Synthesizer instance name\n        anonymize (Optional[str]): (optional) fields to anonymize and the anonymization strategy\n    \"\"\"\nif self._is_initialized():\nraise AlreadyFittedError()\n_datatype = DataSourceType(datatype) if isinstance(\nX, pdDataFrame) else DataSourceType(X.datatype)\ndataset_attrs = self._init_datasource_attributes(\nsortbykey, entity_id_cols, generate_cols, exclude_cols, dtypes)\nself._validate_datasource_attributes(X, dataset_attrs, _datatype, target)\n# If the training data is a pandas dataframe, we first need to create a data source and then the instance\nif isinstance(X, pdDataFrame):\nif X.empty:\nraise EmptyDataError(\"The DataFrame is empty\")\n_X = LocalDataSource(source=X, datatype=_datatype, client=self._client)\nelse:\nif datatype != _datatype:\nwarn(\"When the training data is a DataSource, the argument `datatype` is ignored.\",\nDataSourceTypeWarning)\n_X = X\nif _X.status != dsStatus.AVAILABLE:\nraise DataSourceNotAvailableError(\nf\"The datasource '{_X.uid}' is not available (status = {_X.status.value})\")\nif isinstance(dataset_attrs, dict):\ndataset_attrs = DataSourceAttrs(**dataset_attrs)\nself._fit_from_datasource(\nX=_X, dataset_attrs=dataset_attrs, target=target, name=name, anonymize=anonymize, privacy_level=privacy_level)\n</code></pre>"},{"location":"reference/api/synthesizers/base/#ydata.sdk.synthesizers.synthesizer.BaseSynthesizer.get","title":"<code>get(uid, client=None)</code>  <code>staticmethod</code>","text":"<p>List the synthesizer instances.</p> <p>Parameters:</p> Name Type Description Default <code>uid</code> <code>str</code> <p>synthesizer instance uid</p> required <code>client</code> <code>Client</code> <p>(optional) Client to connect to the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>BaseSynthesizer</code> <p>Synthesizer instance</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/synthesizers/synthesizer.py</code> <pre><code>@staticmethod\n@init_client\ndef get(uid: str, client: Optional[Client] = None) -&gt; \"BaseSynthesizer\":\n\"\"\"List the synthesizer instances.\n    Arguments:\n        uid (str): synthesizer instance uid\n        client (Client): (optional) Client to connect to the backend\n    Returns:\n        Synthesizer instance\n    \"\"\"\nresponse = client.get(f'/synthesizer/{uid}')\ndata: list = response.json()\nmodel, synth_cls = BaseSynthesizer._model_from_api(\ndata['dataSource']['dataType'], data)\nreturn ModelFactoryMixin._init_from_model_data(synth_cls, model)\n</code></pre>"},{"location":"reference/api/synthesizers/base/#ydata.sdk.synthesizers.synthesizer.BaseSynthesizer.list","title":"<code>list(client=None)</code>  <code>staticmethod</code>","text":"<p>List the synthesizer instances.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>Client</code> <p>(optional) Client to connect to the backend</p> <code>None</code> <p>Returns:</p> Type Description <code>SynthesizersList</code> <p>List of synthesizers</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/synthesizers/synthesizer.py</code> <pre><code>@staticmethod\n@init_client\ndef list(client: Optional[Client] = None) -&gt; SynthesizersList:\n\"\"\"List the synthesizer instances.\n    Arguments:\n        client (Client): (optional) Client to connect to the backend\n    Returns:\n        List of synthesizers\n    \"\"\"\ndef __process_data(data: list) -&gt; list:\nto_del = ['metadata', 'report', 'mode']\nfor e in data:\nfor k in to_del:\ne.pop(k, None)\nreturn data\nresponse = client.get('/synthesizer')\ndata: list = response.json()\ndata = __process_data(data)\nreturn SynthesizersList(data)\n</code></pre>"},{"location":"reference/api/synthesizers/base/#ydata.sdk.synthesizers.synthesizer.BaseSynthesizer.sample","title":"<code>sample()</code>  <code>abstractmethod</code>","text":"<p>Abstract method to sample from a synthesizer.</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/synthesizers/synthesizer.py</code> <pre><code>@abstractmethod\ndef sample(self) -&gt; pdDataFrame:\n\"\"\"Abstract method to sample from a synthesizer.\"\"\"\n</code></pre>"},{"location":"reference/api/synthesizers/base/#privacylevel","title":"PrivacyLevel","text":"<p>         Bases: <code>Enum</code></p> <p>Privacy level exposed to the end-user.</p>"},{"location":"reference/api/synthesizers/base/#ydata.datascience.common.privacy.PrivacyLevel.BALANCED_PRIVACY_FIDELITY","title":"<code>BALANCED_PRIVACY_FIDELITY = auto()</code>  <code>class-attribute</code>","text":"<p>Balanced privacy/fidelity</p>"},{"location":"reference/api/synthesizers/base/#ydata.datascience.common.privacy.PrivacyLevel.HIGH_FIDELITY","title":"<code>HIGH_FIDELITY = auto()</code>  <code>class-attribute</code>","text":"<p>High fidelity</p>"},{"location":"reference/api/synthesizers/base/#ydata.datascience.common.privacy.PrivacyLevel.HIGH_PRIVACY","title":"<code>HIGH_PRIVACY = auto()</code>  <code>class-attribute</code>","text":"<p>High privacy</p>"},{"location":"reference/api/synthesizers/regular/","title":"Regular","text":"<p>         Bases: <code>BaseSynthesizer</code></p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/synthesizers/regular.py</code> <pre><code>class RegularSynthesizer(BaseSynthesizer):\ndef sample(self, n_samples: int = 1) -&gt; pdDataFrame:\n\"\"\"Sample from a [`RegularSynthesizer`][ydata.sdk.synthesizers.RegularSynthesizer]\n        instance.\n        Arguments:\n            n_samples (int): number of rows in the sample\n        Returns:\n            synthetic data\n        \"\"\"\nif n_samples &lt; 1:\nraise InputError(\"Parameter 'n_samples' must be greater than 0\")\nreturn self._sample(payload={\"numberOfRecords\": n_samples})\ndef fit(self, X: Union[DataSource, pdDataFrame],\nprivacy_level: PrivacyLevel = PrivacyLevel.HIGH_FIDELITY,\nentity_id_cols: Optional[Union[str, List[str]]] = None,\ngenerate_cols: Optional[List[str]] = None,\nexclude_cols: Optional[List[str]] = None,\ndtypes: Optional[Dict[str, Union[str, DataType]]] = None,\ntarget: Optional[str] = None,\nname: Optional[str] = None,\nanonymize: Optional[dict] = None) -&gt; None:\n\"\"\"Fit the synthesizer.\n        The synthesizer accepts as training dataset either a pandas [`DataFrame`][pandas.DataFrame] directly or a YData [`DataSource`][ydata.sdk.datasources.DataSource].\n        Arguments:\n            X (Union[DataSource, pandas.DataFrame]): Training dataset\n            privacy_level (PrivacyLevel): Synthesizer privacy level (defaults to high fidelity)\n            entity_id_cols (Union[str, List[str]]): (optional) columns representing entities ID\n            generate_cols (List[str]): (optional) columns that should be synthesized\n            exclude_cols (List[str]): (optional) columns that should not be synthesized\n            dtypes (Dict[str, Union[str, DataType]]): (optional) datatype mapping that will overwrite the datasource metadata column datatypes\n            target (Optional[str]): (optional) Target column\n            name (Optional[str]): (optional) Synthesizer instance name\n            anonymize (Optional[str]): (optional) fields to anonymize and the anonymization strategy\n        \"\"\"\nBaseSynthesizer.fit(self, X=X, datatype=DataSourceType.TABULAR, entity_id_cols=entity_id_cols,\ngenerate_cols=generate_cols, exclude_cols=exclude_cols, dtypes=dtypes,\ntarget=target, name=name, anonymize=anonymize, privacy_level=privacy_level)\ndef __repr__(self):\nif self._model is not None:\nreturn self._model.__repr__()\nelse:\nreturn \"RegularSynthesizer(Not Initialized)\"\n</code></pre>"},{"location":"reference/api/synthesizers/regular/#ydata.sdk.synthesizers.regular.RegularSynthesizer.fit","title":"<code>fit(X, privacy_level=PrivacyLevel.HIGH_FIDELITY, entity_id_cols=None, generate_cols=None, exclude_cols=None, dtypes=None, target=None, name=None, anonymize=None)</code>","text":"<p>Fit the synthesizer.</p> <p>The synthesizer accepts as training dataset either a pandas <code>DataFrame</code> directly or a YData <code>DataSource</code>.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[DataSource, pandas.DataFrame]</code> <p>Training dataset</p> required <code>privacy_level</code> <code>PrivacyLevel</code> <p>Synthesizer privacy level (defaults to high fidelity)</p> <code>PrivacyLevel.HIGH_FIDELITY</code> <code>entity_id_cols</code> <code>Union[str, List[str]]</code> <p>(optional) columns representing entities ID</p> <code>None</code> <code>generate_cols</code> <code>List[str]</code> <p>(optional) columns that should be synthesized</p> <code>None</code> <code>exclude_cols</code> <code>List[str]</code> <p>(optional) columns that should not be synthesized</p> <code>None</code> <code>dtypes</code> <code>Dict[str, Union[str, DataType]]</code> <p>(optional) datatype mapping that will overwrite the datasource metadata column datatypes</p> <code>None</code> <code>target</code> <code>Optional[str]</code> <p>(optional) Target column</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>(optional) Synthesizer instance name</p> <code>None</code> <code>anonymize</code> <code>Optional[str]</code> <p>(optional) fields to anonymize and the anonymization strategy</p> <code>None</code> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/synthesizers/regular.py</code> <pre><code>def fit(self, X: Union[DataSource, pdDataFrame],\nprivacy_level: PrivacyLevel = PrivacyLevel.HIGH_FIDELITY,\nentity_id_cols: Optional[Union[str, List[str]]] = None,\ngenerate_cols: Optional[List[str]] = None,\nexclude_cols: Optional[List[str]] = None,\ndtypes: Optional[Dict[str, Union[str, DataType]]] = None,\ntarget: Optional[str] = None,\nname: Optional[str] = None,\nanonymize: Optional[dict] = None) -&gt; None:\n\"\"\"Fit the synthesizer.\n    The synthesizer accepts as training dataset either a pandas [`DataFrame`][pandas.DataFrame] directly or a YData [`DataSource`][ydata.sdk.datasources.DataSource].\n    Arguments:\n        X (Union[DataSource, pandas.DataFrame]): Training dataset\n        privacy_level (PrivacyLevel): Synthesizer privacy level (defaults to high fidelity)\n        entity_id_cols (Union[str, List[str]]): (optional) columns representing entities ID\n        generate_cols (List[str]): (optional) columns that should be synthesized\n        exclude_cols (List[str]): (optional) columns that should not be synthesized\n        dtypes (Dict[str, Union[str, DataType]]): (optional) datatype mapping that will overwrite the datasource metadata column datatypes\n        target (Optional[str]): (optional) Target column\n        name (Optional[str]): (optional) Synthesizer instance name\n        anonymize (Optional[str]): (optional) fields to anonymize and the anonymization strategy\n    \"\"\"\nBaseSynthesizer.fit(self, X=X, datatype=DataSourceType.TABULAR, entity_id_cols=entity_id_cols,\ngenerate_cols=generate_cols, exclude_cols=exclude_cols, dtypes=dtypes,\ntarget=target, name=name, anonymize=anonymize, privacy_level=privacy_level)\n</code></pre>"},{"location":"reference/api/synthesizers/regular/#ydata.sdk.synthesizers.regular.RegularSynthesizer.sample","title":"<code>sample(n_samples=1)</code>","text":"<p>Sample from a <code>RegularSynthesizer</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>n_samples</code> <code>int</code> <p>number of rows in the sample</p> <code>1</code> <p>Returns:</p> Type Description <code>pdDataFrame</code> <p>synthetic data</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/synthesizers/regular.py</code> <pre><code>def sample(self, n_samples: int = 1) -&gt; pdDataFrame:\n\"\"\"Sample from a [`RegularSynthesizer`][ydata.sdk.synthesizers.RegularSynthesizer]\n    instance.\n    Arguments:\n        n_samples (int): number of rows in the sample\n    Returns:\n        synthetic data\n    \"\"\"\nif n_samples &lt; 1:\nraise InputError(\"Parameter 'n_samples' must be greater than 0\")\nreturn self._sample(payload={\"numberOfRecords\": n_samples})\n</code></pre>"},{"location":"reference/api/synthesizers/regular/#privacylevel","title":"PrivacyLevel","text":"<p>         Bases: <code>Enum</code></p> <p>Privacy level exposed to the end-user.</p>"},{"location":"reference/api/synthesizers/regular/#ydata.datascience.common.privacy.PrivacyLevel.BALANCED_PRIVACY_FIDELITY","title":"<code>BALANCED_PRIVACY_FIDELITY = auto()</code>  <code>class-attribute</code>","text":"<p>Balanced privacy/fidelity</p>"},{"location":"reference/api/synthesizers/regular/#ydata.datascience.common.privacy.PrivacyLevel.HIGH_FIDELITY","title":"<code>HIGH_FIDELITY = auto()</code>  <code>class-attribute</code>","text":"<p>High fidelity</p>"},{"location":"reference/api/synthesizers/regular/#ydata.datascience.common.privacy.PrivacyLevel.HIGH_PRIVACY","title":"<code>HIGH_PRIVACY = auto()</code>  <code>class-attribute</code>","text":"<p>High privacy</p>"},{"location":"reference/api/synthesizers/timeseries/","title":"TimeSeries","text":"<p>         Bases: <code>BaseSynthesizer</code></p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/synthesizers/timeseries.py</code> <pre><code>class TimeSeriesSynthesizer(BaseSynthesizer):\ndef sample(self, n_entities: int) -&gt; pdDataFrame:\n\"\"\"Sample from a [`TimeSeriesSynthesizer`][ydata.sdk.synthesizers.TimeSeriesSynthesizer] instance.\n        If a training dataset was not using any `entity` column, the Synthesizer assumes a single entity.\n        A [`TimeSeriesSynthesizer`][ydata.sdk.synthesizers.TimeSeriesSynthesizer] always sample the full trajectory of its entities.\n        Arguments:\n            n_entities (int): number of entities to sample.\n        Returns:\n            synthetic data\n        \"\"\"\nif n_entities is not None and n_entities &lt; 1:\nraise InputError(\"Parameter 'n_entities' must be greater than 0\")\nreturn self._sample(payload={\"numberOfRecords\": n_entities})\ndef fit(self, X: Union[DataSource, pdDataFrame],\nsortbykey: Optional[Union[str, List[str]]],\nprivacy_level: PrivacyLevel = PrivacyLevel.HIGH_FIDELITY,\nentity_id_cols: Optional[Union[str, List[str]]] = None,\ngenerate_cols: Optional[List[str]] = None,\nexclude_cols: Optional[List[str]] = None,\ndtypes: Optional[Dict[str, Union[str, DataType]]] = None,\ntarget: Optional[str] = None,\nname: Optional[str] = None,\nanonymize: Optional[dict] = None) -&gt; None:\n\"\"\"Fit the synthesizer.\n        The synthesizer accepts as training dataset either a pandas [`DataFrame`][pandas.DataFrame] directly or a YData [`DataSource`][ydata.sdk.datasources.DataSource].\n        Arguments:\n            X (Union[DataSource, pandas.DataFrame]): Training dataset\n            sortbykey (Union[str, List[str]]): column(s) to use to sort timeseries datasets\n            privacy_level (PrivacyLevel): Synthesizer privacy level (defaults to high fidelity)\n            entity_id_cols (Union[str, List[str]]): (optional) columns representing entities ID\n            generate_cols (List[str]): (optional) columns that should be synthesized\n            exclude_cols (List[str]): (optional) columns that should not be synthesized\n            dtypes (Dict[str, Union[str, DataType]]): (optional) datatype mapping that will overwrite the datasource metadata column datatypes\n            target (Optional[str]): (optional) Metadata associated to the datasource\n            name (Optional[str]): (optional) Synthesizer instance name\n            anonymize (Optional[str]): (optional) fields to anonymize and the anonymization strategy\n        \"\"\"\nBaseSynthesizer.fit(self, X=X, datatype=DataSourceType.TIMESERIES, sortbykey=sortbykey,\nentity_id_cols=entity_id_cols, generate_cols=generate_cols, exclude_cols=exclude_cols,\ndtypes=dtypes, target=target, name=name, anonymize=anonymize, privacy_level=privacy_level)\ndef __repr__(self):\nif self._model is not None:\nreturn self._model.__repr__()\nelse:\nreturn \"TimeSeriesSynthesizer(Not Initialized)\"\n</code></pre>"},{"location":"reference/api/synthesizers/timeseries/#ydata.sdk.synthesizers.timeseries.TimeSeriesSynthesizer.fit","title":"<code>fit(X, sortbykey, privacy_level=PrivacyLevel.HIGH_FIDELITY, entity_id_cols=None, generate_cols=None, exclude_cols=None, dtypes=None, target=None, name=None, anonymize=None)</code>","text":"<p>Fit the synthesizer.</p> <p>The synthesizer accepts as training dataset either a pandas <code>DataFrame</code> directly or a YData <code>DataSource</code>.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[DataSource, pandas.DataFrame]</code> <p>Training dataset</p> required <code>sortbykey</code> <code>Union[str, List[str]]</code> <p>column(s) to use to sort timeseries datasets</p> required <code>privacy_level</code> <code>PrivacyLevel</code> <p>Synthesizer privacy level (defaults to high fidelity)</p> <code>PrivacyLevel.HIGH_FIDELITY</code> <code>entity_id_cols</code> <code>Union[str, List[str]]</code> <p>(optional) columns representing entities ID</p> <code>None</code> <code>generate_cols</code> <code>List[str]</code> <p>(optional) columns that should be synthesized</p> <code>None</code> <code>exclude_cols</code> <code>List[str]</code> <p>(optional) columns that should not be synthesized</p> <code>None</code> <code>dtypes</code> <code>Dict[str, Union[str, DataType]]</code> <p>(optional) datatype mapping that will overwrite the datasource metadata column datatypes</p> <code>None</code> <code>target</code> <code>Optional[str]</code> <p>(optional) Metadata associated to the datasource</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>(optional) Synthesizer instance name</p> <code>None</code> <code>anonymize</code> <code>Optional[str]</code> <p>(optional) fields to anonymize and the anonymization strategy</p> <code>None</code> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/synthesizers/timeseries.py</code> <pre><code>def fit(self, X: Union[DataSource, pdDataFrame],\nsortbykey: Optional[Union[str, List[str]]],\nprivacy_level: PrivacyLevel = PrivacyLevel.HIGH_FIDELITY,\nentity_id_cols: Optional[Union[str, List[str]]] = None,\ngenerate_cols: Optional[List[str]] = None,\nexclude_cols: Optional[List[str]] = None,\ndtypes: Optional[Dict[str, Union[str, DataType]]] = None,\ntarget: Optional[str] = None,\nname: Optional[str] = None,\nanonymize: Optional[dict] = None) -&gt; None:\n\"\"\"Fit the synthesizer.\n    The synthesizer accepts as training dataset either a pandas [`DataFrame`][pandas.DataFrame] directly or a YData [`DataSource`][ydata.sdk.datasources.DataSource].\n    Arguments:\n        X (Union[DataSource, pandas.DataFrame]): Training dataset\n        sortbykey (Union[str, List[str]]): column(s) to use to sort timeseries datasets\n        privacy_level (PrivacyLevel): Synthesizer privacy level (defaults to high fidelity)\n        entity_id_cols (Union[str, List[str]]): (optional) columns representing entities ID\n        generate_cols (List[str]): (optional) columns that should be synthesized\n        exclude_cols (List[str]): (optional) columns that should not be synthesized\n        dtypes (Dict[str, Union[str, DataType]]): (optional) datatype mapping that will overwrite the datasource metadata column datatypes\n        target (Optional[str]): (optional) Metadata associated to the datasource\n        name (Optional[str]): (optional) Synthesizer instance name\n        anonymize (Optional[str]): (optional) fields to anonymize and the anonymization strategy\n    \"\"\"\nBaseSynthesizer.fit(self, X=X, datatype=DataSourceType.TIMESERIES, sortbykey=sortbykey,\nentity_id_cols=entity_id_cols, generate_cols=generate_cols, exclude_cols=exclude_cols,\ndtypes=dtypes, target=target, name=name, anonymize=anonymize, privacy_level=privacy_level)\n</code></pre>"},{"location":"reference/api/synthesizers/timeseries/#ydata.sdk.synthesizers.timeseries.TimeSeriesSynthesizer.sample","title":"<code>sample(n_entities)</code>","text":"<p>Sample from a <code>TimeSeriesSynthesizer</code> instance.</p> <p>If a training dataset was not using any <code>entity</code> column, the Synthesizer assumes a single entity. A <code>TimeSeriesSynthesizer</code> always sample the full trajectory of its entities.</p> <p>Parameters:</p> Name Type Description Default <code>n_entities</code> <code>int</code> <p>number of entities to sample.</p> required <p>Returns:</p> Type Description <code>pdDataFrame</code> <p>synthetic data</p> Source code in <code>/opt/hostedtoolcache/Python/3.10.10/x64/lib/python3.10/site-packages/ydata/sdk/synthesizers/timeseries.py</code> <pre><code>def sample(self, n_entities: int) -&gt; pdDataFrame:\n\"\"\"Sample from a [`TimeSeriesSynthesizer`][ydata.sdk.synthesizers.TimeSeriesSynthesizer] instance.\n    If a training dataset was not using any `entity` column, the Synthesizer assumes a single entity.\n    A [`TimeSeriesSynthesizer`][ydata.sdk.synthesizers.TimeSeriesSynthesizer] always sample the full trajectory of its entities.\n    Arguments:\n        n_entities (int): number of entities to sample.\n    Returns:\n        synthetic data\n    \"\"\"\nif n_entities is not None and n_entities &lt; 1:\nraise InputError(\"Parameter 'n_entities' must be greater than 0\")\nreturn self._sample(payload={\"numberOfRecords\": n_entities})\n</code></pre>"},{"location":"reference/api/synthesizers/timeseries/#privacylevel","title":"PrivacyLevel","text":"<p>         Bases: <code>Enum</code></p> <p>Privacy level exposed to the end-user.</p>"},{"location":"reference/api/synthesizers/timeseries/#ydata.datascience.common.privacy.PrivacyLevel.BALANCED_PRIVACY_FIDELITY","title":"<code>BALANCED_PRIVACY_FIDELITY = auto()</code>  <code>class-attribute</code>","text":"<p>Balanced privacy/fidelity</p>"},{"location":"reference/api/synthesizers/timeseries/#ydata.datascience.common.privacy.PrivacyLevel.HIGH_FIDELITY","title":"<code>HIGH_FIDELITY = auto()</code>  <code>class-attribute</code>","text":"<p>High fidelity</p>"},{"location":"reference/api/synthesizers/timeseries/#ydata.datascience.common.privacy.PrivacyLevel.HIGH_PRIVACY","title":"<code>HIGH_PRIVACY = auto()</code>  <code>class-attribute</code>","text":"<p>High privacy</p>"},{"location":"support/help-troubleshooting/","title":"Help &amp; Troubleshooting","text":""}]}