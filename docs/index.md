# Welcome

[YData Fabric](https://ydata.ai/products/fabric) is a **Data-Centric AI** development platform that accelerates
AI development by helping data practitioners achieve production-quality data.

Much like for software engineering the quality of code is a must for the success of software development, Fabric
accounts for the data quality requirements for data-driven applications. It introduces standards, processes, and 
acceleration to empower data science, analytics, and data engineering teams.

**(Add here the image from the website - I've already created the img folder to centralize all the doc images)**

### Try Fabric
- [Get started with Fabric community](get-started/fabric_community.md)

## Why adopt YData Fabric?

With Fabric, you can standardize the understanding of your data, quickly identify data quality issues, streamline and
version your data preparation workflows and finally leverage synthetic data for privacy-compliance or as a tool to boost ML
performance. Fabric is a development environment that supports a faster and easier process of preparing data for AI development.
Data practitioners are using Fabric to: 

- Establish a centralized and collaborative repository for data projects.
- Create and share comprehensive documentation of data, encompassing data schema, structure, and personally identifiable information (PII)
- Prevent data quality issues with standardized data quality profiling, providing visual understanding and warnings on potential issues.
- Accelerate data preparation with customizable recipes.
- Improve machine learning performance with optimal data preparation through solutions like as synthetic data
- Shorten access to data with privacy-compliant synthetic data generation
- Build and streamline data preparation workflows effortlessly through a user-friendly drag-and-drop interface.
- Efficiently manage business rules, conduct comparisons, and implement version control for data workflows using pipelines.

## üìù Key features

### Data Catalog
[Fabric Data Catalog](https://ydata.ai/products/data_catalog) provides a centralized perspective on datasets within a project-basis, optimizing data management
through seamless integration with the organization's existing data architectures via scalable connectors (e.g., MySQL, Google Cloud Storage, AWS S3).
It standardizes data quality profiling, streamlining the processes of efficient data cleaning and preparation,
while also automating the identification of Personally Identifiable Information (PII) to facilitate compliance with privacy regulations.

Add here a CTA to get started or see the Data Catalog in action.

### Labs

Fabric's Labs environments provide collaborative, scalable, and secure workspaces layered on a flexible infrastructure, enabling users to
seamlessly switch between CPUs and GPUs based on their computational needs. Labs are familiar environments that empower data developers with
powerful IDEs (Jupyter Notebooks, Visual Code or H2O flow) and a seamless experience with the tools they already love combined with YData's
cutting-edge SDK for data preparation.

Add here the CTA to get started with the Labs.

### Synthetic data
Synthetic data, enabled by YData Fabric, provides data developers with a user-friendly interfaces (UI and code) for
generating artificial datasets, offering a versatile solution across formats like tabular, time-series and multi-table datasets.
The generated synthetic data holds the same value of the original and aligns intricately with specific business rules, contributing
to machine learning models enhancement, mitigation of privacy concerns and more robustness for data developments.
Fabric offers synthetic data that is ease to adapt and configure, allows customization in what concerns privacy-utility trade-offs.

Add here the CTA to see get started with Synthetic data generation - a tutorial or a small video link.

### Pipelines
Fabric Pipelines streamlines data preparation workflows by automating, orchestrating, and optimizing data pipelines,
providing benefits such as flexibility, scalability, monitoring, and reproducibility for efficient and reliable data processing.
The intuitive drag-and-drop interface, leveraging Jupyter notebooks or Python scripts, expedites the pipeline setup process,
providing data developers with a quick and user-friendly experience.

Add here the CTA to get started with the Pipelines

### Tutorials

We have use cases in the academy that we can link here as part of the tutorials - https://github.com/ydataai/academy/tree/master/4%20-%20Use%20Cases

## üôã Support
Need help? Want to share a perspective? Report a bug? Ideas for collaborations? Reach out via the following channels:

(Update with the channels that we use for Fabric)
